{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ID_KTRAIN_RoBERTa_noemojis_#3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnZUCAY3gJdy"
      },
      "source": [
        "###This notebook:\n",
        "+ ktrain\n",
        "+ hugging face transformers\n",
        "+ roberta-base\n",
        "+ lower LR 5e-5 + triangular policy\n",
        "+ remove emojis\n",
        "\n",
        "07/07:\n",
        "accuracy .75\n",
        "\n",
        "Note: weight file has been moved into model folder - move out if it causes problems when loading predictor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsA6CWMAT0uI"
      },
      "source": [
        "###Check Requirements/imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_nz4p-OPXku",
        "outputId": "921bb7a0-966c-46a5-f1ac-f45fff2e7742"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oROUW-h1TQw3"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXVbEHgBgBlx"
      },
      "source": [
        "pip install emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYa80vPv1WYq"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M7RCXHz8hWP"
      },
      "source": [
        "!pip3 install -q ktrain "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8cV_JeIXhR"
      },
      "source": [
        "pip install -U sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8p1iY_PIjju"
      },
      "source": [
        "pip install parse_version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-w3Pesk__N7"
      },
      "source": [
        "pip install git+https://github.com/amaiya/eli5@tfkeras_0_10_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JVnyWxljMXa",
        "outputId": "be15ce66-290e-481a-9e61-df7f5813c1ff"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n",
            "Version:  2.5.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtoMyb5pI2t5",
        "outputId": "1c031e9f-a140-4798-82c9-58e3875f5af2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex6H4bqQ4UUh"
      },
      "source": [
        "###Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAcBtc5jrNjm"
      },
      "source": [
        "# Load train data\n",
        "train_path = '/content/drive/MyDrive/TeamLab/data/semeval_taskA_corrected.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_path, header=0, names=['index',\n",
        "                                                    'irony_label',\n",
        "                                                    'tweet'])\n",
        "                                                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "BZudUweLsJsA",
        "outputId": "cb734894-2cf9-4c9e-cf33-71fb1611a521"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>irony_label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sweet United Nations video. Just in time for C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left I'm dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  irony_label                                              tweet\n",
              "0      1            1  Sweet United Nations video. Just in time for C...\n",
              "1      2            1  @mrdahl87 We are rumored to have talked to Erv...\n",
              "2      3            1  Hey there! Nice to see you Minnesota/ND Winter...\n",
              "3      4            0                3 episodes left I'm dying over here\n",
              "4      5            1  I can't breathe! was chosen as the most notabl..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhan_Km_scxz",
        "outputId": "d7e9724b-87e4-4213-984b-e7529c8d57c5"
      },
      "source": [
        "# Check if dataset is balanced\n",
        "\n",
        "# Classes are 1 and 0. Tweet can either be ironic or non-ironic -> binary classification\n",
        "classes = df_train.irony_label.unique()\n",
        "\n",
        "print((df_train.irony_label == 0).sum())\n",
        "print((df_train.irony_label == 1).sum())\n",
        "\n",
        "# => Balanced"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1923\n",
            "1911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "uyP21KPctkwj",
        "outputId": "4d7b8c18-e5b9-4a72-8ed2-4a3836479d6c"
      },
      "source": [
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/TeamLab/data/semeval_taskA_test.csv'\n",
        "\n",
        "df_test = pd.read_csv(test_path, sep='\\t', header=0, names=['index',\n",
        "                                                            'irony_label',\n",
        "                                                            'tweet'])\n",
        "\n",
        "print((df_test.irony_label == 0).sum())\n",
        "print((df_test.irony_label == 1).sum())\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "473\n",
            "311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>irony_label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@Callisto1947 Can U Help?||More conservatives ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>#NOT GONNA WIN http://t.co/Mc9ebqjAqj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>@mickymantell He is exactly that sort of perso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  irony_label                                              tweet\n",
              "0      1            0  @Callisto1947 Can U Help?||More conservatives ...\n",
              "1      2            1  Just walked in to #Starbucks and asked for a \"...\n",
              "2      3            0              #NOT GONNA WIN http://t.co/Mc9ebqjAqj\n",
              "3      4            0  @mickymantell He is exactly that sort of perso...\n",
              "4      5            1  So much #sarcasm at work mate 10/10 #boring 10..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERcod8R_t1iG"
      },
      "source": [
        "x_train = df_train['tweet'].to_numpy()\n",
        "y_train = df_train['irony_label'].to_numpy()\n",
        "\n",
        "x_test = df_test['tweet'].to_numpy()\n",
        "y_test = df_test['irony_label'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2rUez8ST_vZ"
      },
      "source": [
        "###Normalisation of input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN7SF1FIehwQ"
      },
      "source": [
        "Normalise:\n",
        "+ hashtags\n",
        "+ tagged users\n",
        "+ emoji (+ ones that are made up of characters e.g. :P)\n",
        "+ urls \n",
        "+ laugh (haha, lol..)\n",
        "+ remove stops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdeAu-6VdSzP"
      },
      "source": [
        "import emoji\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "import contractions\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def normalise_tweet(tweet):\n",
        "    norm_tweet = re.sub(\"&\", \"and\", tweet)\n",
        "    norm_tweet = re.sub(r\"[<>]\", \"\", norm_tweet)\n",
        "    norm_tweet = re.sub(\"http:.*\", \"url\", norm_tweet)\n",
        "    norm_tweet = re.sub(\"@\", \" @\", norm_tweet)\n",
        "    norm_tweet = re.sub(\"#\", \" \", norm_tweet)\n",
        "\n",
        "    norm_tweet = emoji.demojize(norm_tweet)\n",
        "    # Remove emojis\n",
        "    norm_tweet = re.sub(\": ?[a-z][a-z]+.*[a-z]+ ?:\", \"\", norm_tweet)\n",
        "    \n",
        "    norm_tweet = re.sub(r\"[-()/_;:{}=~|,\\[\\]]\", \" \", norm_tweet)\n",
        "\n",
        "    norm_tweet = contractions.fix(norm_tweet)\n",
        "\n",
        "    tokenizer = TweetTokenizer()\n",
        "    final_tweet = ''\n",
        "\n",
        "    for token in tokenizer.tokenize(norm_tweet):\n",
        "        if token.startswith(\"@\"):\n",
        "            token = \"tagged_user\"\n",
        "        if token.isnumeric():\n",
        "            token = \"digit\"\n",
        "\n",
        "        final_tweet += token + \" \"\n",
        "        \n",
        "    return final_tweet.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jbMJYIjfo24"
      },
      "source": [
        "x_train_norm = []\n",
        "for tweet in x_train:\n",
        "    x_train_norm.append(normalise_tweet(tweet))\n",
        "\n",
        "x_test_norm = []\n",
        "for tweet in x_test:\n",
        "    x_test_norm.append(normalise_tweet(tweet))\n",
        "\n",
        "x_train_norm = np.array(x_train_norm)\n",
        "x_test_norm = np.array(x_test_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m0cb8dhCru4",
        "outputId": "5aff928d-e471-4c14-cbdf-23fd28f18162"
      },
      "source": [
        "x_train_norm[10:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Oh thank GOD our entire office email system is down ... the day of a big event . Santa you know JUST what to get me for xmas .',\n",
              "       'But instead I am scrolling through Facebook Instagram and Twitter for hours on end accomplishing nothing .',\n",
              "       'tagged_user no he bloody is not I was upstairs getting changed !',\n",
              "       \"Cold or warmth both suffuse one's cheeks with pink colour tone ... Do you understand the underlying difference and its texture ?\",\n",
              "       'Just great when you are mobile bill arrives by text',\n",
              "       'crushes are great until you realize they will never be interested in you . p',\n",
              "       'Buffalo sports media is smarter than all of us . Where else can you get the quality insight offered by Harrington and Busgaglia .',\n",
              "       'I guess my cat also lost digit pounds when she went to the vet after I have been feeding her a few times a day . Eating food WorkingOut',\n",
              "       'tagged_user tagged_user Rosenthal trading a SP for a defense only SS ? Brilliant trade .',\n",
              "       'But tagged_user was trying to find us and my battery died . Guess how he found us ? Yes that bastard wand ! ! ! !'],\n",
              "      dtype='<U167')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79QK8pfYvikz",
        "outputId": "0298d68f-f3a1-40c6-e24b-fe656e5be879"
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "seq_len = []\n",
        "\n",
        "idx = 0\n",
        "for tweet in x_train_norm:\n",
        "    if len(tweet.split()) > 35:\n",
        "        print(idx, tweet)\n",
        "    seq_len.append(len(tweet.split()))\n",
        "    idx += 1\n",
        "\n",
        "print(max(seq_len))\n",
        "print(mean(seq_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "888 This time change is crazy . everyone is all up here like woohoo its 11am let us live life ! and I am like it is 5am and I have not slept at all yet .\n",
            "948 Kyle it will not let me tagged_user you ? But yeah we are grown ass men with fast cars . Who gives af lol . And bring it to my room hooah ? See ya in a bit .\n",
            "39\n",
            "15.141627543035995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFJczzkYej3l"
      },
      "source": [
        "##Model (ktrain, roberta-base)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "M00inrBI7wFQ",
        "outputId": "4d6605a2-8906-4b53-f73f-431fada80b09"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "\n",
        "categories = [0, 1]\n",
        "\n",
        "MODEL_NAME = 'roberta-base'\n",
        "\n",
        "# Transormer is a wrapper to the Hugging Face transformers library for text classification.\n",
        "t = text.Transformer(MODEL_NAME, maxlen=100, class_names=categories)\n",
        "\n",
        "# Using normalised input data\n",
        "trn = t.preprocess_train(x_train_norm, y_train)\n",
        "val = t.preprocess_test(x_test_norm, y_test)\n",
        "\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 16\n",
            "\t95percentile : 27\n",
            "\t99percentile : 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REMh0YXmNm_C"
      },
      "source": [
        "###Estimate LR\n",
        "\n",
        "run the following to let ktrain stimate a good LR\n",
        "\n",
        "learner.lr_find(show_plot=True, max_epochs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugo9iFmzesxj"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXI9twirgYY_"
      },
      "source": [
        "best_lr = 5e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9cTJdxwKpol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bba50b7-9f8c-46f2-eb7c-a1ebedff8707"
      },
      "source": [
        "# Train\n",
        "# Parameters: LR, epochs\n",
        "# LR==(5e-5)\n",
        "\n",
        "learner.autofit(lr=best_lr, checkpoint_folder='/my_models', verbose=1)\n",
        "\n",
        "# if epochs is None, then early_stopping and reduce_on_plateau are atomatically set to 6 and 3, respectively.\n",
        "# if lr missing, it will be estimated (initial lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "early_stopping automatically enabled at patience=5\n",
            "reduce_on_plateau automatically enabled at patience=2\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 5e-05...\n",
            "Epoch 1/1024\n",
            "240/240 [==============================] - 98s 352ms/step - loss: 0.6581 - accuracy: 0.5962 - val_loss: 0.6245 - val_accuracy: 0.6594\n",
            "Epoch 2/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.5865 - accuracy: 0.6875 - val_loss: 0.5742 - val_accuracy: 0.7130\n",
            "Epoch 3/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.4998 - accuracy: 0.7613 - val_loss: 0.5880 - val_accuracy: 0.7462\n",
            "Epoch 4/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.4169 - accuracy: 0.8054 - val_loss: 0.6207 - val_accuracy: 0.7321\n",
            "\n",
            "Epoch 00004: Reducing Max LR on Plateau: new max lr will be 2.5e-05 (if not early_stopping).\n",
            "Epoch 5/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.2842 - accuracy: 0.8837 - val_loss: 0.7939 - val_accuracy: 0.6939\n",
            "Epoch 6/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.1895 - accuracy: 0.9264 - val_loss: 0.8206 - val_accuracy: 0.7181\n",
            "\n",
            "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 1.25e-05 (if not early_stopping).\n",
            "Epoch 7/1024\n",
            "240/240 [==============================] - 84s 346ms/step - loss: 0.1155 - accuracy: 0.9596 - val_loss: 1.0394 - val_accuracy: 0.7270\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00007: early stopping\n",
            "Weights from best epoch have been loaded into model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac77e41e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PUwKE0AexrR"
      },
      "source": [
        "###Evaluate/Inspect model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFGGSCdmKqFm",
        "outputId": "165fe755-e298-47c9-e90f-ebc3ee09e0e5"
      },
      "source": [
        "learner.validate(class_names=t.get_classes())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.66      0.73       473\n",
            "           1       0.60      0.80      0.69       311\n",
            "\n",
            "    accuracy                           0.71       784\n",
            "   macro avg       0.72      0.73      0.71       784\n",
            "weighted avg       0.74      0.71      0.72       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[311, 162],\n",
              "       [ 63, 248]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpagsGmZZSNw"
      },
      "source": [
        "# Set weights to those of the best epoch\n",
        "learner.model.load_weights('/my_models/weights-03.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8_HU65ZhiO",
        "outputId": "b0efc13d-8a24-471e-e21b-83fa1078ae7c"
      },
      "source": [
        "learner.validate(class_names=t.get_classes())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.71      0.77       473\n",
            "           1       0.65      0.79      0.71       311\n",
            "\n",
            "    accuracy                           0.75       784\n",
            "   macro avg       0.74      0.75      0.74       784\n",
            "weighted avg       0.76      0.75      0.75       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[338, 135],\n",
              "       [ 64, 247]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLxcMrvYONHR",
        "outputId": "f8e6bd5a-7528-47bc-a800-2b85c1f6f5f4"
      },
      "source": [
        "# the ones that we got most wrong\n",
        "learner.view_top_losses(n=10, preproc=t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "id:618 | loss:5.21 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:5 | loss:5.1 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:330 | loss:4.75 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:700 | loss:4.45 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:587 | loss:4.41 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:676 | loss:4.2 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:505 | loss:4.19 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:43 | loss:4.09 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:169 | loss:4.01 | true:0 | pred:1)\n",
            "\n",
            "----------\n",
            "id:629 | loss:3.95 | true:0 | pred:1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdn3Opy0fATN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9290fbd-6427-4445-89d5-9a2e398c33cf"
      },
      "source": [
        "# print out instance to see why...\n",
        "print(x_test_norm[618])\n",
        "print(x_test_norm[5])\n",
        "print(x_test_norm[330])\n",
        "print(x_test_norm[700])\n",
        "print(x_test_norm[587])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Love it when my mans on a cleaning spree .. Saves me doing it OK hand\n",
            "Corny jokes are my absolute favorite\n",
            "Sarcasm makes you mentally stronger . Which is very effective when dealing with emotional stress and fustration . funfact WhatIfISay\n",
            "Today was a very good day in Iceland .\n",
            "That awkward moment when you plane your whole day around your Golf Class and it gets cancelled ! stupidrain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFN47ZM3fTUb"
      },
      "source": [
        "###Make predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MAGrx_mOchU"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfseXcxYfjrt"
      },
      "source": [
        "test_sent = ('Cool it is raining again')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu9KTMs5OhZb",
        "outputId": "c9e629ce-2481-4e6f-b8da-dd8fea303674"
      },
      "source": [
        "predictor.predict(test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeLecvXROwgt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "3cadaedf-053d-4c4d-e875-0a58080f17d1"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.569</b>, score <b>0.276</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.735\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.62%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.459\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 67.47%); opacity: 0.95\" title=\"1.213\">cool</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.29%); opacity: 0.91\" title=\"0.867\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.631\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.68%); opacity: 0.89\" title=\"0.709\">raining</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.32%); opacity: 0.88\" title=\"-0.680\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1N5nS-ObqFZ"
      },
      "source": [
        "more_sents = ['Going to the dentist for a root canal this afternoon. Yay, I can’t wait.', \n",
        "              'It was so nice of my dad to come to my graduation party. #not', \n",
        "              'I drank a healthy, homemade fruit smoothie...in a Budweiser glass #irony', \n",
        "              'Dogs are really cute, one day I want to live in a big house with many dogs', \n",
        "              'some trees are really tall, others not so much', \n",
        "              'just came back from dinner at Nandos with my mates']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odOXKSEYab-J",
        "outputId": "944a9590-e6e3-4093-cba9-4ec955a91317"
      },
      "source": [
        "predictor.predict(more_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "ijjXP9wfdfuV",
        "outputId": "e742a0a2-7b3d-4b59-b7c1-ef183759fa08"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.995</b>, score <b>5.261</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.082\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.08%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.821\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 95.35%); opacity: 0.81\" title=\"0.216\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.48%); opacity: 0.81\" title=\"0.276\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.24%); opacity: 0.81\" title=\"0.293\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.49%); opacity: 0.83\" title=\"0.600\">dentist</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.11%); opacity: 0.81\" title=\"0.232\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.27%); opacity: 0.80\" title=\"0.101\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.68%); opacity: 0.81\" title=\"0.261\">root</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.67%); opacity: 0.81\" title=\"0.335\">canal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.61%); opacity: 0.80\" title=\"0.084\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.46%); opacity: 0.83\" title=\"0.791\">afternoon</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"4.668\">yay</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.95%); opacity: 0.81\" title=\"0.177\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.51%); opacity: 0.82\" title=\"0.510\">can</span><span style=\"opacity: 0.80\">’</span><span style=\"background-color: hsl(120, 100.00%, 90.15%); opacity: 0.83\" title=\"0.631\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.11%); opacity: 0.84\" title=\"0.824\">wait</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "Rf8CjcyTecE8",
        "outputId": "fe8b0854-8755-4c91-856e-a70ed1906294"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.947</b>, score <b>2.881</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.781\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.68%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.900\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 93.81%); opacity: 0.81\" title=\"-0.219\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.67%); opacity: 0.81\" title=\"0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.39%); opacity: 0.92\" title=\"1.955\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.156\">nice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.92%); opacity: 0.83\" title=\"-0.505\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.69%); opacity: 0.80\" title=\"-0.003\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.43%); opacity: 0.84\" title=\"0.674\">dad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.79%); opacity: 0.82\" title=\"0.273\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.16%); opacity: 0.82\" title=\"0.365\">come</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.54%); opacity: 0.83\" title=\"0.529\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.59%); opacity: 0.81\" title=\"-0.094\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.81%); opacity: 0.83\" title=\"0.511\">graduation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.66%); opacity: 0.81\" title=\"-0.227\">party</span><span style=\"opacity: 0.80\">. #</span><span style=\"background-color: hsl(0, 100.00%, 95.19%); opacity: 0.81\" title=\"-0.153\">not</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "IPUqFkKhdsOU",
        "outputId": "3c5d080d-a392-478e-abad-aa2b86419e3e"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.943</b>, score <b>2.804</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.810\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 92.12%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.007\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 99.56%); opacity: 0.80\" title=\"0.005\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.22%); opacity: 0.86\" title=\"0.995\">drank</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.82%); opacity: 0.83\" title=\"0.512\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.29%); opacity: 0.83\" title=\"0.482\">healthy</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.90%); opacity: 0.81\" title=\"0.216\">homemade</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.15%); opacity: 0.82\" title=\"-0.255\">fruit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.79%); opacity: 0.82\" title=\"0.389\">smoothie</span><span style=\"opacity: 0.80\">...</span><span style=\"background-color: hsl(120, 100.00%, 90.09%); opacity: 0.83\" title=\"0.431\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.11%); opacity: 0.84\" title=\"0.628\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.68%); opacity: 0.93\" title=\"2.132\">budweiser</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.22%); opacity: 0.83\" title=\"-0.487\">glass</span><span style=\"opacity: 0.80\"> #</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.167\">irony</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "oFT5McnddsiE",
        "outputId": "34d9b1ab-a17e-4aa0-bfc6-c5782c59fe75"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.483</b>, score <b>-0.067</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 81.03%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.850\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.917\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 97.40%); opacity: 0.80\" title=\"-0.033\">dogs</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.33%); opacity: 0.82\" title=\"-0.128\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.24%); opacity: 0.93\" title=\"1.088\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.659\">cute</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 91.06%); opacity: 0.82\" title=\"-0.195\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.60%); opacity: 0.83\" title=\"0.210\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.35%); opacity: 0.82\" title=\"-0.186\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.03%); opacity: 0.88\" title=\"-0.659\">want</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.10%); opacity: 0.80\" title=\"-0.007\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.09%); opacity: 0.82\" title=\"0.135\">live</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.95%); opacity: 0.83\" title=\"0.231\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.31%); opacity: 0.83\" title=\"0.252\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.80%); opacity: 0.83\" title=\"0.269\">big</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.24%); opacity: 0.83\" title=\"0.254\">house</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.85%); opacity: 0.83\" title=\"0.267\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.38%); opacity: 0.83\" title=\"0.284\">many</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.67%); opacity: 0.84\" title=\"0.345\">dogs</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "iPdOV1PcecYr",
        "outputId": "86ac6345-1ced-479d-cdca-ec8d1ba0f125"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.667</b>, score <b>-0.693</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.761\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.068\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 97.90%); opacity: 0.80\" title=\"-0.018\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.25%); opacity: 0.82\" title=\"-0.140\">trees</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.95%); opacity: 0.80\" title=\"0.007\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.68%); opacity: 0.93\" title=\"-0.788\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.228\">tall</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 88.14%); opacity: 0.84\" title=\"0.216\">others</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.95%); opacity: 0.87\" title=\"0.425\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.55%); opacity: 0.84\" title=\"-0.232\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.32%); opacity: 0.81\" title=\"-0.057\">much</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "ukzu0COOemCs",
        "outputId": "11c88aad-ca86-45fa-be12-d74e95bd8f93"
      },
      "source": [
        "# Ask for explanation\n",
        "predictor.explain(more_sents[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.566</b>, score <b>-0.265</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.991\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.92%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.726\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 82.36%); opacity: 0.86\" title=\"-0.225\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.28%); opacity: 0.94\" title=\"-0.497\">came</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.33%); opacity: 0.90\" title=\"-0.363\">back</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.25%); opacity: 0.98\" title=\"-0.642\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.02%); opacity: 0.82\" title=\"0.072\">dinner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.94%); opacity: 0.91\" title=\"-0.393\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.27%); opacity: 0.88\" title=\"-0.303\">nandos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.47%); opacity: 0.84\" title=\"-0.154\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.07%); opacity: 0.84\" title=\"-0.161\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.724\">mates</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x780FVL3dFej"
      },
      "source": [
        "###Save + Reload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aewjelXlbcU1"
      },
      "source": [
        "predictor.save('/my_models/ID_RoBERTa_noemojis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6WdiWbEbtBO"
      },
      "source": [
        "# Reload to check that model has been saved correctly\n",
        "reloaded_predictor = ktrain.load_predictor('/my_models/ID_RoBERTa_noemojis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSc0fyYrbz3w",
        "outputId": "22d2f70d-0962-42af-fa5e-b89935c47d04"
      },
      "source": [
        "reloaded_predictor.predict(test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikj-RNoLb-T1",
        "outputId": "b2069703-3760-450e-ac7c-9b0b34b3c2a1"
      },
      "source": [
        "# Do reloaded_predictor and original predictor give the same numbers?\n",
        "reloaded_predictor.predict_proba(test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03814947, 0.9618505 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrjAufCjfLpM",
        "outputId": "95d6d6f1-1bd0-43e9-fb67-4ad703491bd8"
      },
      "source": [
        "predictor.predict_proba(test_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03814947, 0.9618505 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeyAN_EDcDdD",
        "outputId": "66447b18-4faa-4d1b-ad9a-adecf195bb9a"
      },
      "source": [
        "reloaded_predictor.get_classes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aacbUV3_hnaw",
        "outputId": "74abf5ca-f7ec-48a2-e006-6eceabc59aa5"
      },
      "source": [
        "# Copy model files to drive - files on google colab disk space are temporary and get deleted when the session is over\n",
        "\n",
        "%cp -av \"/content/my_models/ID_RoBERTa_noemojis\" \"/content/drive/MyDrive/TeamLab/my_models\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/my_models/ID_RoBERTa_noemojis' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/config.json' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/config.json'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/tf_model.h5' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/tf_model.h5'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/tokenizer_config.json' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/tokenizer_config.json'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/special_tokens_map.json' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/special_tokens_map.json'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/vocab.json' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/vocab.json'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/merges.txt' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/merges.txt'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/tf_model.preproc' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/tf_model.preproc'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/weights-03.hdf5' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/weights-03.hdf5'\n",
            "'/content/my_models/ID_RoBERTa_noemojis/.ipynb_checkpoints' -> '/content/drive/MyDrive/TeamLab/my_models/ID_RoBERTa_noemojis/.ipynb_checkpoints'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG2Qqm0biw7J"
      },
      "source": [
        "\n",
        "To load and continue training\n",
        "```\n",
        "# save model and Preprocessor instance after partially training\n",
        "ktrain.get_predictor(model, preproc).save('/tmp/my_predictor')\n",
        "\n",
        "# reload Predictor and extract model\n",
        "model = ktrain.load_predictor('/tmp/my_predictor').model\n",
        "\n",
        "# re-instantiate Learner and continue training\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val)\n",
        "learner.fit_onecycle(2e-5, 1)\n",
        "```\n",
        "\n"
      ]
    }
  ]
}